{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1779d667-58c1-4758-9593-e7372d7094dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cifar100\"\n",
    "iterations = \"2,2,2,2\"\n",
    "u_channels = \"256,256,256,256\"\n",
    "f_channels = \"256,256,256,256\"\n",
    "batch_size = 1024\n",
    "epochs = 150\n",
    "epoch_step = 30\n",
    "lr = .1\n",
    "lr_step = 10\n",
    "momentum = .9\n",
    "wd = .0005\n",
    "graph = True\n",
    "\n",
    "iterations = [int(x) for x in iterations.split(\",\")]\n",
    "u_channels = [int(x) for x in u_channels.split(\",\")]\n",
    "f_channels = [int(x) for x in f_channels.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "110092fb-21d8-43ad-9647-23c553c84e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aae112eb-50d0-4b98-90d1-2f768d69307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    dataset,\n",
    "    split = [\"train\", \"test\"],\n",
    "    shuffle_files = True,\n",
    "    as_supervised = True,\n",
    "    with_info = True)\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "  mean, variance = [.1307], [.3081]\n",
    "if dataset == \"cifar10\":\n",
    "  mean, variance = [.4914, .4822, .4465], [.2023, .1994, .2010]\n",
    "if dataset == \"cifar100\":\n",
    "  mean, variance = [.5071, .4865, .4409], [.2673, .2564, .2762]\n",
    "normalize = tf.keras.layers.Normalization(mean = mean,\n",
    "                                          variance = variance)\n",
    "train_layers = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomTranslation(height_factor = .125,\n",
    "                                    width_factor = .125,\n",
    "                                    fill_mode = \"constant\"),\n",
    "  tf.keras.layers.RandomRotation(factor = .08,\n",
    "                                 fill_mode = \"constant\"),\n",
    "  tf.keras.layers.RandomFlip(mode = \"horizontal\"),\n",
    "  normalize\n",
    "])\n",
    "test_layers = tf.keras.Sequential([normalize])\n",
    "\n",
    "def preprocess(ds, layers):\n",
    "  ds = ds.map(lambda x, y: (layers(x), y),\n",
    "              num_parallel_calls = tf.data.AUTOTUNE)\n",
    "  ds = ds.cache()\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "  return ds\n",
    "\n",
    "ds_train = preprocess(ds_train, train_layers)\n",
    "ds_test = preprocess(ds_test, test_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00340774-1918-40b6-bdc7-4a5d22b1c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MgSmooth(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, iterations, u_channels, f_channels):\n",
    "    super(MgSmooth, self).__init__()\n",
    "\n",
    "    self.iterations = iterations\n",
    "    self.A = tf.keras.layers.Conv2D(u_channels,\n",
    "                                    (3, 3),\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = \"same\",\n",
    "                                    use_bias = False)\n",
    "    self.B = tf.keras.layers.Conv2D(f_channels,\n",
    "                                    (3, 3),\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = \"same\",\n",
    "                                    use_bias = False)\n",
    "\n",
    "    self.A_bns, self.B_bns = [], []\n",
    "    for _ in range(self.iterations):\n",
    "      self.A_bns.append(tf.keras.layers.BatchNormalization())\n",
    "      self.B_bns.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  def call(self, u, f):\n",
    "    for i in range(self.iterations):\n",
    "      error = tf.nn.relu(self.A_bns[i](f - self.A(u)))\n",
    "      u = u + tf.nn.relu(self.B_bns[i](self.B(error)))\n",
    "    return u, f\n",
    "\n",
    "class MgBlock(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, iterations, u_channels, f_channels, A_old):\n",
    "    super(MgBlock, self).__init__()\n",
    "\n",
    "    self.iterations = iterations\n",
    "    self.Pi = tf.keras.layers.Conv2D(u_channels,\n",
    "                                     (3, 3),\n",
    "                                     strides = (2, 2),\n",
    "                                     padding = \"same\",\n",
    "                                     use_bias = False)\n",
    "    self.R = tf.keras.layers.Conv2D(f_channels,\n",
    "                                    (3, 3),\n",
    "                                    strides = (2, 2),\n",
    "                                    padding = \"same\",\n",
    "                                    use_bias = False)\n",
    "    self.A_old = A_old\n",
    "    self.MgSmooth = MgSmooth(self.iterations, u_channels, f_channels)\n",
    "\n",
    "    self.Pi_bn = tf.keras.layers.BatchNormalization()\n",
    "    self.R_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, u0, f0):\n",
    "    u1 = tf.nn.relu(self.Pi_bn(self.Pi(u0)))\n",
    "    error = tf.nn.relu(self.R_bn(self.R(f0 - self.A_old(u0))))\n",
    "    f1 = error + self.MgSmooth.A(u1)\n",
    "    u, f = self.MgSmooth(u1, f1)\n",
    "    return u, f\n",
    "\n",
    "class MgNet(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, iterations, u_channels, f_channels, in_shape, out_shape):\n",
    "    super(MgNet, self).__init__()\n",
    "\n",
    "    self.iterations = iterations\n",
    "    self.in_shape = in_shape\n",
    "    self.A_init = tf.keras.layers.Conv2D(u_channels[0],\n",
    "                                         (3, 3),\n",
    "                                         strides = (1, 1),\n",
    "                                         padding = \"same\",\n",
    "                                         use_bias = False)\n",
    "    self.A_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.blocks = []\n",
    "    for i in range(len(self.iterations)):\n",
    "      if i == 0:\n",
    "        self.blocks.append(MgSmooth(iterations[i],\n",
    "                                    u_channels[i],\n",
    "                                    f_channels[i]))\n",
    "        continue\n",
    "      if i == 1:\n",
    "        self.blocks.append(MgBlock(iterations[i],\n",
    "                                   u_channels[i],\n",
    "                                   f_channels[i],\n",
    "                                   self.blocks[0].A))\n",
    "        continue\n",
    "      self.blocks.append(MgBlock(iterations[i],\n",
    "                                 u_channels[i],\n",
    "                                 f_channels[i],\n",
    "                                 self.blocks[i - 1].MgSmooth.A))\n",
    "\n",
    "    x = in_shape[0]\n",
    "    for i in range(len(self.blocks) - 1):\n",
    "      x = ((x + 2 - 3) // 2) + 1\n",
    "    self.pool = tf.keras.layers.AveragePooling2D(pool_size = (x, x))\n",
    "    self.softmax = tf.keras.layers.Dense(out_shape,\n",
    "                                         activation = \"softmax\")\n",
    "  \n",
    "  def call(self, u0):\n",
    "    f = tf.nn.relu(self.A_bn(self.A_init(u0)))\n",
    "    u = tf.multiply(f, 0)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      u, f = block(u, f)\n",
    "    u = self.pool(u)\n",
    "    u = tf.squeeze(u, [-2, -3])\n",
    "    u = self.softmax(u)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59e45c82-9eae-42dd-9dab-f291eb6047fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 09:53:51.809632: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "390/391 [============================>.] - ETA: 0s - loss: 4.2442 - accuracy: 0.0626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 09:54:55.569813: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 70s 83ms/step - loss: 4.2434 - accuracy: 0.0627 - val_loss: 4.3691 - val_accuracy: 0.0510 - lr: 0.1000\n",
      "Epoch 2/150\n",
      "391/391 [==============================] - 20s 51ms/step - loss: 3.6693 - accuracy: 0.1323 - val_loss: 4.1946 - val_accuracy: 0.0940 - lr: 0.1000\n",
      "Epoch 3/150\n",
      " 49/391 [==>...........................] - ETA: 15s - loss: 3.4746 - accuracy: 0.1649"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122112/3731271116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                       callbacks = [lr_s])\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "  if (epoch + 1) % epoch_step == 0:\n",
    "    return lr / lr_step\n",
    "  return lr\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "with strategy.scope():\n",
    "  model = MgNet(iterations = iterations,\n",
    "                u_channels = u_channels,\n",
    "                f_channels = f_channels,\n",
    "                in_shape = ds_info.features[\"image\"].shape,\n",
    "                out_shape = ds_info.features[\"label\"].num_classes)\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "  lr_s = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "  optimizer = tfa.optimizers.SGDW(learning_rate = lr,\n",
    "                                  weight_decay = wd,\n",
    "                                  momentum = momentum)\n",
    "  \n",
    "  model.compile(optimizer = optimizer,\n",
    "                loss = loss,\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "  history = model.fit(ds_train,\n",
    "                      epochs = epochs,\n",
    "                      validation_data = ds_test,\n",
    "                      callbacks = [lr_s])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609c21a-9301-487a-ab14-4bb270321d37",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if graph:\n",
    "  loss = history.history[\"loss\"]\n",
    "  accuracy = history.history[\"accuracy\"]\n",
    "  val_loss = history.history[\"val_loss\"]\n",
    "  val_accuracy = history.history[\"val_accuracy\"]\n",
    "  timerange = range(len(loss))\n",
    "\n",
    "  fig,ax = plt.subplots()\n",
    "  train_loss_plot, = ax.plot(timerange, loss, color = \"blue\")\n",
    "  val_loss_plot, = ax.plot(timerange, val_loss, color = \"cyan\")\n",
    "  train_loss_plot.set_label(\"Train Loss\")\n",
    "  val_loss_plot.set_label(\"Validation Loss\")\n",
    "  ax.set_xlabel(\"Epoch\")\n",
    "  ax.set_ylabel(\"Loss\")\n",
    "  ax.legend(loc = \"upper left\")\n",
    "  ax2 = ax.twinx()\n",
    "  train_acc_plot, = ax2.plot(timerange, accuracy, color = \"purple\")\n",
    "  val_acc_plot, = ax2.plot(timerange, val_accuracy, color = \"pink\")\n",
    "  train_acc_plot.set_label(\"Train Accuracy\")\n",
    "  val_acc_plot.set_label(\"Validation Accuracy\")\n",
    "  ax2.set_ylabel(\"Accuracy\")\n",
    "  ax2.legend(loc = \"upper right\")\n",
    "  plt.title(\"Loss vs Accuracy\")\n",
    "  plt.savefig(f\"{dataset}_mgnet_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9004d1-e44f-4dd1-bcd6-f9dce6e7b426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
